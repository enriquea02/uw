{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 4 Linear Algebra\n",
    "## Additional References\n",
    "| Subject                                           | Reference                                         |\n",
    "| ---                                               | ---                                               |\n",
    "| | |\n",
    "\n",
    "## Notation\n",
    "### Matrices\n",
    "| Math Language             | English Translation                                                                                   |\n",
    "| ---                       | ---                                                                                                   |\n",
    "| $[A]_{ij}$                | Value at row $i$ and column $j$ of matrix $A$                                                         |\n",
    "\n",
    "### Determinant of a Matrix\n",
    "| Math Language             | English Translation                                                                                   |\n",
    "| ---                       | ---                                                                                                   |\n",
    "| $A(i\\|j)$                 | $submatrix$ $\\|$ $(m-1) \\times (n-1)$ matrix obtained from $A$ with row $i$ and column $j$ removed    |\n",
    "| $\\|X\\|$                   | determinant                                                                                           |\n",
    "| $det(X)$                  | determinant                                                                                           |\n",
    "\n",
    "### Eigenvalues\n",
    "| Math Language             | English Translation                                                                                   |\n",
    "| ---                       | ---                                                                                                   |\n",
    "| $\\lambda$                 | eigenvalue of a vector                                                                                |\n",
    "| $p_A(x)$                  | polynomial of matrix A                                                                                |\n",
    "| $\\varepsilon_A(\\lambda)$  | eigenspace of $A$ for $\\lambda$                                                                       |\n",
    "\n",
    "## Language\n",
    "### Eigenvalues\n",
    "| Math Language                         | English Translation                                                                       |\n",
    "| ---                                   | ---                                                                                       |\n",
    "| $A \\textbf{x} = \\lambda \\textbf{x}$   | $x$ is an eigenvector of $A$ with eigenvalue $\\lambda$                                    |\n",
    "\n",
    "## Dictionary\n",
    "### Vectors\n",
    "| Math Word                 | Definition                                        |\n",
    "| ---                       | ---                                               |\n",
    "| subspace                  | subspace = subset of vector space                 |\n",
    "| span                      | span = num of sets of vectors                     |\n",
    "| basis                     | linearly independent set of vectors across span   |\n",
    "| vector space              | span of a basis                                   |    \n",
    "\n",
    "### Matrices\n",
    "| Math Word                 | Definition                                                            |\n",
    "| ---                       | ---                                                                   |\n",
    "| rank                      | is the number of linearly independent rows (or columns) in a matrix   |\n",
    "\n",
    "### Determinants\n",
    "| Math Word                 | Definition                                            |\n",
    "| ---                       | ---                                                   |\n",
    "| Submatrix                 | Used to compute determinant, composed of matrix $A$   |\n",
    "\n",
    "\n",
    "## Notes\n",
    "### Systems of Linear Equations\n",
    "### Vectors \n",
    "### Matrices\n",
    "### Vector Spaces\n",
    "\n",
    "### Determinant of Matrix\n",
    "Defines the space (volume) that matrix will occupy. Visualize size through graph area encompassed. <br>\n",
    "\n",
    "If $det(M) = 0$, then matrix is singular. \n",
    "<br>\n",
    "Visually, linear dependence implies graph volume is zero and $n$ dimensional matrix is reduced to $(n-1)$ dimensions. i.e. $3D$ matrix $\\rightarrow$ 2D matrix\n",
    "\n",
    "#### Compute Determinant(s)\n",
    "Decompose $matrix$ into $submatrix$. <br>\n",
    "Matrices of size 1 are their own determinant. $$ \\text{If A is a } 1 \\times 1 \\text{ matrix, } det(A) = [A]_{11} $$\n",
    "Matrices of size $n$ with $n \\geq 2$, $$det(A) = [A]_{11}det(A(1|1)) - [A]_{12}det(A(1|2)) + [A]_{13}det(A(1|3)) - [A]_{14}det(A(1|4)) + ... + (-1)^{n+1}[A]_{1n}det(A(1|n))$$\n",
    "Breaking down the above formula, $[A]_{11}$ represents a single value in the matrix indexed by $row$ then $column$. Meanwhile, $det(A(1|1))$ represents the new submatrix that will be formed after removing row 1 and column 1 from matrix A to form the submatrix.\n",
    "\n",
    "Determinant of a square matrix can be expanded through either rows or columns. For any $n$ sized matrix, use $i$ to represent the rows and $j$ to represent the columns. \n",
    "$$ 1 \\leq i \\leq n \\text{; } 1 \\leq j \\leq n$$\n",
    "$$\\text{Row representation: } (-1)^{i+1}[A]_{i1}det(A(i|1))$$\n",
    "$$\\text{Column representation: } (-1)^{1+j}[A]_{1j}det(A(1|j))$$\n",
    "<br>\n",
    "Determinants for $3x3$ matrices, okay to hand eval if contains lots of zeroes. Google or $nxn$ > $3x3$.\n",
    "\n",
    "#### Determinant Properities\n",
    "1. Assuming $A$ is a square matrix and $A^t$ is the transpose, $$det(A^{t}) = det(A)$$\n",
    "2. Assuming $A$ is a square matrix with with a row or column of zeroes, $$det(A) = 0$$\n",
    "A zero row/column indicates a singular matrix or a dimension that's ill-defined.\n",
    "<br>\n",
    "<br>\n",
    "3. Row Operations impact the determinant \n",
    "<br>\n",
    "<br>\n",
    "Row/Column swap; assume $B$ is equal to $A$ with rows 1 & 2 swapped, $$det(B) = -det(A)$$\n",
    "Scalar Multiplication of single Row/Column; assume $B$ is equal to $A$ with row 1 multiplied by scalar value $\\alpha$, $$det(B) = \\alpha det(A)$$ \n",
    "Row/Column Multiples and Addition; assume $B$ is equal to $A$ with row/column 1 multiplied by a value and added to row/column 2 of $A$, $$det(B) = det(A)$$\n",
    "4. Equal Row/Column in matrix $A$, $$det(A) = 0$$\n",
    "Equal rows/columns indicate linear independece in the matrix.\n",
    "<br>\n",
    "<br>\n",
    "5. All matrices with determinants are non-singular\n",
    "6. Determinant respects matrix multiplication, $$det(AB) = det(A)det(B)$$\n",
    "7. Determinant of identity matrix is 1, $$det(I_n) = 1$$\n",
    "\n",
    "### Eigenvalues\n",
    "$\\lambda$ is a scalar in $\\mathbb{C}$ <br>\n",
    "$x$ is a vector in $\\mathbb{C^n}$, where $n$ is the size of vector $x$. <br>\n",
    "<br>\n",
    "Matrices can be substituted into polynomials variables. <br>\n",
    "<br>\n",
    "$\\textbf{Theorem: All square matrices have at least one eigenvalue}$\n",
    "\n",
    "#### Properities of Eigenvalues\n",
    "1. Eigenvectors with distinct eigenvalues are linearly independent. \n",
    "$$ A \\text{ is a } nxn \\text{ matrix and } S = {x_1, x_2, x_3, ... , x_p} \\text{ is a set of eigenvectors with eigenvalues } \\lambda_1, \\lambda_2, \\lambda_3, ... ,\\lambda_p. \\text{ For all } \\lambda_i \\neq \\lambda_j \\text{ whenever } i \\neq j, \\text{ then the } S \\text{ is linearly independent.} $$\n",
    "2. Singular matrices have zero eigenvalues\n",
    "3. Inverse to 2., matrices with $\\lambda \\neq 0$ are non-singular\n",
    "4. Scalar Multiplication: If a matrix has an eigenvalue, then is multiplied by a scalar, then the new eigenvalue is the original eigenvalue of the matrix multiplied by the scalar\n",
    "$$ \\text{ If A has } \\lambda, \\text{ then } \\alpha A \\text{ has } \\alpha \\lambda$$\n",
    "5. Matrix Powers: assume s $\\geq$ 0, $$\\lambda^{s} is an eigenvalue of A^{s}$$\n",
    "6. Polynomials: If $q(x)$ is a polynomial and $A$, with eigenvalue $\\lambda$ is an input to $q(x)$, then $q(A)$ has eigenvalue $q(\\lambda)$\n",
    "7.\n",
    "8.\n",
    "9. \n",
    "\n",
    "#### Computing Eigenvalues\n",
    "$(A - \\lambda I_n) \\textbf{x} = 0$, assuming $\\textbf{x} \\neq 0$ and is an nonzero element of the null space of the matrix $(A - \\lambda I_n)$, that means matrix $(A - \\lambda I_n)$ is singular and has a zero determinant.\n",
    "\n",
    "$\\text{determinant} \\rightarrow \\text{characteristic polynomial} \\rightarrow \\text{eigenvalues}$ <br>\n",
    "Solve for characteristic polynomial, $$p_A (x) = det(A - x I_n)$$\n",
    "Roots of p_A (x) gives $\\lambda$, $$p_A (\\lambda) = 0$$\n",
    "\n",
    "#### Eigenspaces\n",
    "Solves for eigenvectors, if matrix $A$ and eigenvalues are known.<br>\n",
    "Each $\\lambda$ for $A$ has at least one eigenvector, includes zero vector.<br>\n",
    "All eigenspaces are subspaces of vector space of $C^n$ <br>\n",
    "$$\\varepsilon_A(\\lambda)  = \\mathbb{N}(A - \\lambda I_n)$$\n",
    "\n",
    "### Similarity\n",
    "Matrices are similar if there exists a nonsingular matrix of equal dimensions, S_{nxn}, such that $$A = S^{-1}B{S}$$\n",
    "\n",
    "#### Properities of Similarity\n",
    "1. Similar matrices share the same eigenvalues and characteristic polynomial <br>\n",
    "Reverse is not true, matrices with the same eigenvalues does not imply similarity\n",
    "2. Similarity is an Equivalence Relation <br>\n",
    "Reflexive; $A$ is similar to $A$ <br>\n",
    "Symmetric; If $A$ is similar to $B$, then $B$ is similar to $A$ <br>\n",
    "Transitive; If $A$ is similar to $B$ and $B$ is is similar to $C$, then $A$ is similar to $C$\n",
    "\n",
    "### Diagnolization\n",
    "\n",
    "### Jordan Canonical Form\n",
    "### The Caley-Hamilton Theorem\n",
    "### The Matrix Exponential\n",
    "### Singular Value Decompisition\n",
    "\n",
    "\n",
    "\n",
    "## Questions\n",
    "1. Why does a vector space equal zero when determining linear independence?\n",
    "2. How did people figure out matrix operation properities? Is it born through set operations?\n",
    "3. Do vector spaces composed of complex numbers still fall under Real Analysis?\n",
    "4. How are matrices graphed? What maps to x and y, or is it a multi-axes graph >2 axes?\n",
    "5. Is matrix rank related to vector linear independence? yes, ideal is to have a matrix $nxn$ has all linearly independent rows, meaning all rows are unique \n",
    "6. Why are vector spaces and matrices composed of numbers in the complex domain?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
