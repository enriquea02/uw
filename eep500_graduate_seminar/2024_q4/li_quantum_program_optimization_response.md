Graduate Seminar Paper <br>
Enrique Antunano <br>

The quantum computing material Dr. Li presented was new material outside my expertise. During my undergraduate education in the late 2010s, I talked to my peers and heard their guesses that quantum computing was a few years away from a boom. At that time, IBM was the leader in quantum computing and there were news articles that Google would be jumping in as well. During Dr. Li's introduction, the history of quantum computing was summarized and I realized my undergraduate education was during some big leaps in quantum computing. As a topic that has floated around in the background of my undergraduate education, I am interested to see if there will be rapid changes in the field over the next few years similar to the first computing revolution of the 1960s and 1970s. Currently, I do not have an interest in switching career fields to quantum computing. I think it is important to be aware of updates in the field since they can disrupt aspects of classical computing as quantum computing resources and infrastructure grow.

To prepare the groundwork, Dr. Li described IBM's 5 qubit circuit and a fundamental circuit-level representation of the qubits and accompanying logic gates. As part of the 5 qubit IBM circuit, there was a hardware limitation with data processing between gates since, at the hardware level, not all the gates were directly interconnected. Dr. Li described his initial quantum compiler, which was a tool to determine the optimal combination of qubits and gates to increase the effective qubits available. For example, the quantum compiler broke down software functions into representations that use fewer qubits to achieve the same or similar results. Through scheduling and resource allocation, the quantum compiler, like a classical compiler, is capable of maximizing the usage of limited hardware resources. The data point that stuck out was IBM's benchmarking results from 2022, where the quantum volume of hardware innovations led to an effective, QV = 16, while a combination of hardware plus software compilers led to a QV = 128. From that metric, it made me realize the importance of quantum compilers to make code, targeted on a quantum processor, more efficient so that we can extract as much performance from these machines as possible.

Innovations in quantum computing are important since they will allow for simulations of fundamental physics in a reasonable time frame, which classical computers cannot match. So, as the number of qubits continues to grow due to hardware innovations, quantum compilers must keep up, otherwise, the quantum volume will be limited by hardware innovations even though the great increases in quantum volume come from quantum compilers. Research by Dr. Li on his first quantum compiler algorithm was sufficient for low-count qubit processors, but the latest processors in the tens of qubits need new compilers. The old quantum compiler algorithm is unstable since it requires a $2^n$ matrix to solve, which is unrealistic as the number of qubits scale. Tomorrow's quantum compilers will break down code compilation into stages similar to classical compilers. Staging the workflow allows for different optimizations within each stage which will help prevent the unstable $2^n$ behavior in the first low-count qubit quantum compilers. In his presentation, Dr. Li covered advances in the encoding and algorithm stage but did not touch on the programming or compilation stages, meaning plenty of opportunity for continued advancement in those two subfields.

G. Li, “Quantum Program Optimization and How to Do It at Large Scale,”  presented at the 2024-25 Research Colloquium Series, E. Antunano, Ed.,  UW Department of Electrical & Computer Engineering, Oct. 31, 2024.